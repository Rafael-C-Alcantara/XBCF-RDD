#+PROPERTY: header-args:R :tangle yes :exports results :cache yes
# Fonts
#+latex_header: \usepackage{bbm}
# Math
#+latex_header: \usepackage{amsfonts,amsmath,mathtools}
#+latex_header: \usepackage[linesnumbered,ruled]{algorithm2e}
#+latex_header: \usepackage{dsfont}
# Figures and tables
#+latex_header: \usepackage{graphicx}
#+latex_header: \usepackage{caption}
#+latex_header: \usepackage{subcaption}
#+latex_header: \usepackage{multirow}
# Bibliography
#+latex_header: \usepackage{natbib}
# New commands
#+latex_header: \newcommand{\res}{\mathbf{r}}
#+latex_header: \newcommand{\w}{\mathbf{w}}
#+latex_header: \newcommand{\m}{\mathbf{m}}
#+latex_header: \newcommand{\x}{\mathbf{x}}
#+latex_header: \newcommand{\C}{\mathbb{C}}
#+latex_header: \newcommand{\E}{\mathbb{E}}
#+latex_header: \newcommand{\N}{\mathrm{N}}
#+latex_header: \newtheorem{assumption}{Assumption}[section]
#+latex_header: \newtheorem{theorem}{Theorem}[section]
#+latex_header: \newcommand{\indep}{\perp \!\!\! \perp}
* Previous RDD papers
It is worth noting that most of the papers write the DGPs in
terms of $E[Y_1|X]=\mu_1(x)$ and $E[Y_0|X]=\mu_0(x)$. While
this makes sense from the perspective that most methods
consist of approximating each function and taking their
differences at $x=c$, I rewrite the DGPs in terms of a
prognostic and treatment function, $\mu(x)$ and $\tau(x)$
respectively, as this makes more sense from a BCF
perspective.
** Without W
*** IK2012
cite:imbens2012optimal consider 4 different DGPs. For every
DGP, they consider $n=500$ and sample $X$ from $X \sim 2
\mathcal{B}(2,4) - 1$, $Z = \mathbf{1}(X \geq 0)$ and
$\varepsilon \sim \mathcal{N}(0,0.1295^2)$. For each DGP,
the prognostic and treatment effect functions are defined
as:

1. Based on cite:lee2008randomized[fn:a]:
   - $\mu(x) = 0.48 + 1.27 x + 7.18 x^2 + 20.21 x^3 + 21.54
     x^4 + 7.33 x^5$
   - $\tau(x) = 0.04 - 0.43 x - 10.18 x^2 - 12.22 x^3 - 12.53
     x^4 - 3.77 x^5$
2. Quadratic on X:
   - $\mu(x) = 3 x^2$
   - $\tau(x) = x ^2$
3. Constant ATE:
   - $\mu(x) = 0.42 + 0.84 x - 3 x^2 + 7.99 x^3 - 9.01 x^4 +
     3.56 x^5$
   - $\tau(x) = 0.1$
4. Constant ATE and curvature at the threshold is zero at
   both sides:
   - $\mu(x) = 0.42 + 0.84 x + 7.99 x^3 - 9.01 x^4 + 3.56
     x^5$
   - $\tau(x) = 0.1$

This is what each DGP looks like:

#+BEGIN_SRC R :results output file graphics :file IK2012.pdf
  set.seed(0)
  n <- 500
  x <- 2*rbeta(n,2,4)-1
  z <- as.numeric(x>=0)
  sig <- 0.1295
  mu1 <- function(x) 0.48 + 1.27*x + 7.18*x^2 + 20.21*x^3 + 21.54*x^4 + 7.33*x^5
  tau1 <- function(x) 0.04 - 0.43*x - 10.18*x^2 - 12.22*x^3 - 12.53*x^4 - 3.77*x^5
  mu2 <- function(x) 3*x^2
  tau2 <- function(x) x^2
  mu3 <- function(x) 0.42 + 0.84*x - 3*x^2 + 7.99*x^3 - 9.01*x^4 + 3.56*x^5
  mu4 <- function(x) 0.42 + 0.84*x + 7.99*x^3 - 9.01*x^4 + 3.56*x^5
  tau34 <- 0.1
  y1 <- mu1(x) + tau1(x)*z + rnorm(n,0,sig)
  y2 <- mu2(x) + tau2(x)*z + rnorm(n,0,sig)
  y3 <- mu3(x) + tau34*z + rnorm(n,0,sig)
  y4 <- mu4(x) + tau34*z + rnorm(n,0,sig)
  ##
  par(mfrow=c(2,2))
  plot(x,y1,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y2,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y3,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y4,xlab="X",ylab="Y",col=z+1,bty="n")
#+END_SRC

#+RESULTS[a1b1aa62852d213770d27aeb103550326aa800bc]:
[[file:IK2012.pdf]]

*** CCT2014
cite:calonico2014robust repeat $n$, $X$ and $\varepsilon$
from cite:imbens2012optimal. Their regression functions
follow[fn:b]:

1. Lee data
2. Based on cite:ludwig2007does[fn:c]:
   - $\mu(x) = 3.71 + 2.30 x + 3.28 x^2 + 1.45 x^3 + 0.23
     x^4 + 0.03 x^5$
   - $\tau(x) = -3.45 + 16.19 x - 58.09 x^2 + 72.85 x^3 -
     45.25 x^4 + 9.8 x^5$
3. Variation of Lee data
   - $\mu(x) = 0.48 + 1.27 x - 3.59 x^2 + 14.147 x^3 +
     23.694 x^4 + 10.995 x^5$
   - $\tau(x) = 0.04 - 0.43 x + 3.29 x^2 - 16.544 x^3 -
     24.595 x^4 - 7.435 x^5$

This is what each DGP looks like:

#+BEGIN_SRC R :results output file graphics :file CCT2014.pdf
  set.seed(0)
  n <- 500
  x <- 2*rbeta(n,2,4)-1
  z <- as.numeric(x>=0)
  sig <- 0.1295
  mu1 <- function(x) 0.48 + 1.27*x + 7.18*x^2 + 20.21*x^3 + 21.54*x^4 + 7.33*x^5
  tau1 <- function(x) 0.04 - 0.43*x - 10.18*x^2 - 12.22*x^3 - 12.53*x^4 - 3.77*x^5
  mu2 <- function(x) 3.71 + 2.30*x + 3.28*x^2 + 1.45*x^3 + 0.23*x^4 + 0.03*x^5
  tau2 <- function(x) -3.45 + 16.19*x - 58.09*x^2 + 72.85*x^3 - 45.25*x^4 + 9.8*x^5
  mu3 <- function(x) 0.48 + 1.27*x - 3.59*x^2 + 14.147*x^3 + 23.694*x^4 + 10.995*x^5
  tau3 <- function(x) 0.04 - 0.43*x + 3.29*x^2 - 16.544*x^3 - 24.595*x^4 - 7.435*x^5
  y1 <- mu1(x) + tau1(x)*z + rnorm(n,0,sig)
  y2 <- mu2(x) + tau2(x)*z + rnorm(n,0,sig)
  y3 <- mu3(x) + tau3(x)*z + rnorm(n,0,sig)
  ##
  par(mfrow=c(2,2))
  plot(x,y1,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y2,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y3,xlab="X",ylab="Y",col=z+1,bty="n")
#+END_SRC

#+RESULTS[a256029cd64b28896130186a81372f5eace35743]:
[[file:CCT2014.pdf]]

*** BRBM2019
cite:branson2019nonparametric fit two different GP
regressions to treated and untreated units. They generate
1000 samples of 7 different DGPs. In each case, $n$, $X$ and
$\varepsilon$ are the same as cite:imbens2012optimal. The
regression functions are the same as cite:imbens2012optimal
and cite:calonico2014robust plus one additional setup:

1. Cubic functions:
   - $\mu(x) = 3 x^3$
   - $\tau(x) = x^3$

The DGPs look like this:

#+BEGIN_SRC R :results output graphics file :file BRBM2019.pdf
  set.seed(0)
  n <- 500
  x <- 2*rbeta(n,2,4)-1
  z <- as.numeric(x>=0)
  sig <- 0.1295
  mu1 <- function(x) 0.48 + 1.27*x + 7.18*x^2 + 20.21*x^3 + 21.54*x^4 + 7.33*x^5
  tau1 <- function(x) 0.04 - 0.43*x - 10.18*x^2 - 12.22*x^3 - 12.53*x^4 - 3.77*x^5
  mu2 <- function(x) 3*x^2
  tau2 <- function(x) x^2
  mu3 <- function(x) 0.42 + 0.84*x - 3*x^2 + 7.99*x^3 - 9.01*x^4 + 3.56*x^5
  mu4 <- function(x) 0.42 + 0.84*x + 7.99*x^3 - 9.01*x^4 + 3.56*x^5
  tau34 <- 0.1
  mu5 <- function(x) 3.71 + 2.30*x + 3.28*x^2 + 1.45*x^3 + 0.23*x^4 + 0.03*x^5
  tau5 <- function(x) -3.45 + 16.19*x - 58.09*x^2 + 72.85*x^3 - 45.25*x^4 + 9.8*x^5
  mu6 <- function(x) 0.48 + 1.27*x - 3.59*x^2 + 14.147*x^3 + 23.694*x^4 + 10.995*x^5
  tau6 <- function(x) 0.04 - 0.43*x + 3.29*x^2 - 16.544*x^3 - 24.595*x^4 - 7.435*x^5
  mu7 <- function(x) 3*x^3
  tau7 <- function(x) x^3
  y1 <- mu1(x) + tau1(x)*z + rnorm(n,0,sig)
  y2 <- mu2(x) + tau2(x)*z + rnorm(n,0,sig)
  y3 <- mu3(x) + tau34*z + rnorm(n,0,sig)
  y4 <- mu4(x) + tau34*z + rnorm(n,0,sig)
  y5 <- mu5(x) + tau5(x)*z + rnorm(n,0,sig)
  y6 <- mu6(x) + tau6(x)*z + rnorm(n,0,sig)
  y7 <- mu7(x) + tau7(x)*z + rnorm(n,0,sig)
  ##
  par(mfrow=c(2,4))
  plot(x,y1,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y2,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y3,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y4,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y5,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y6,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y7,xlab="X",ylab="Y",col=z+1,bty="n")
#+END_SRC

#+RESULTS[af123a1d094dbf992a04b88bd9b77a1abd29b6e9]:
[[file:BRBM2019.pdf]]

*** CCF2020
cite:calonico2020optimal consider a variation of the LM data
with a different cutoff and higher error variance, but same
parameters for $\mu$ and $\tau$.
** With W
*** CGS2023
cite:chib2023nonparametric analyzes two DGPs. First, the
classic Lee data with t-distributed erros instead of
Gaussian errors. They also consider a setup with
nonparametric errors as follows. $\mu,\tau$ are an extension
of the Lee data DGP that also includes $W$ but in such a way
that there still are no heterogeneous effects. For this DGP
they also propose a more intricate error structure. The DGP
is:

#+BEGIN_SRC latex
  \begin{equation}
    \begin{split}
      \mu(x,w) &= 0.48 + 1.27 x + 7.18 x^2 + 20.21 x^3 + 21.54 x^4 + 7.33 x^5 + h(w) + \varepsilon_{\mu}\\
      \tau(x,w) &= 0.04 - 0.43 x - 10.18 x^2 - 12.22 x^3 - 12.53 x^4 - 3.77 x^5 + \varepsilon_{\tau}\\
      h(w) &= \frac{\sin(\pi w/2)}{1 + w^2(\text{sign}(w)+1)}\\
      w &\sim U(-\pi,\pi)\\
      \varepsilon_{\mu} &= \varepsilon_0\\
      \varepsilon_{\tau} &= \varepsilon_1 - \varepsilon_0.
    \end{split}
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \begin{split}
    \mu(x,w) &= 0.48 + 1.27 x + 7.18 x^2 + 20.21 x^3 + 21.54 x^4 + 7.33 x^5 + h(w) + \varepsilon_{\mu}\\
    \tau(x,w) &= 0.04 - 0.43 x - 10.18 x^2 - 12.22 x^3 - 12.53 x^4 - 3.77 x^5 + \varepsilon_{\tau}\\
    h(w) &= \frac{\sin(\pi w/2)}{1 + w^2(\text{sign}(w)+1)}\\
    w &\sim U(-\pi,\pi)\\
    \varepsilon_{\mu} &= \varepsilon_0\\
    \varepsilon_{\tau} &= \varepsilon_1 - \varepsilon_0.
  \end{split}
\end{equation}
#+end_export

The errors follow:

#+BEGIN_SRC latex
  \begin{equation}
    \begin{split}
      F(\varepsilon_0) &= \sigma_0 F(\varepsilon)\\
      F(\varepsilon_1) &= \sigma_1 F(\varepsilon)\\
      F(\varepsilon) &= \frac{1}{3} \times \Phi(\varepsilon + 2.5) + \frac{1}{3} \times \Phi(\varepsilon) + \frac{1}{3} \times \Phi(\varepsilon - 2.5)\\
      \sigma_0 &= 0.1295\\
      \sigma_1 &= 0.2.
    \end{split}
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \begin{split}
    F(\varepsilon_0) &= \sigma_0 F(\varepsilon)\\
    F(\varepsilon_1) &= \sigma_1 F(\varepsilon)\\
    F(\varepsilon) &= \frac{1}{3} \times \Phi(\varepsilon + 2.5) + \frac{1}{3} \times \Phi(\varepsilon) + \frac{1}{3} \times \Phi(\varepsilon - 2.5)\\
    \sigma_0 &= 0.1295\\
    \sigma_1 &= 0.2.
  \end{split}
\end{equation}
#+end_export

This is what that second DGP looks like:

#+BEGIN_SRC R :results output file graphics :file cgs2023.pdf
  set.seed(0)
  n <- 500
  x <- 2*rbeta(n,2,4)-1
  z <- as.numeric(x>=0)
  w <- runif(n,-pi,pi)
  sig0 <- 0.1295
  sig1 <- 0.2
  epsilon <- 1/3*rnorm(n,-2.5,1) + 1/3*rnorm(n,0,1) + 1/3*rnorm(n,2.5,1)
  e.mu <- sig0*epsilon
  e.tau <- sig1*epsilon
  mu <- function(x,w,e) 0.48 + 1.27*x + 7.18*x^2 + 20.21*x^3 + 21.54*x^4 + 7.33*x^5 + sin(pi*w/2)/(1+w^2*(sign(w)+1)) + e
  tau <- function(x,e) 0.04 - 0.43*x - 10.18*x^2 - 12.22*x^3 - 12.53*x^4 - 3.77*x^5 + e
  y <- mu(x,w,e.mu) + tau(x,e.tau-e.mu)*z
  ##
  y.axis <- c(min(density(e.mu)$y,density(e.tau-e.mu)$y),max(density(e.mu)$y,density(e.tau-e.mu)$y))
  par(mfrow=c(2,1))
  plot(density(e.mu),col=2,bty="n",ylim=y.axis,main="")
  lines(density(e.tau-e.mu),col=3)
  legend("topright",col=2:3,lty=1,legend=c(expression(epsilon[mu]),expression(epsilon[tau])))
  plot(x,y,xlab="X",ylab="Y",col=z+1,bty="n")
#+END_SRC

#+RESULTS[916ac30ae26d94de1051674f1ce8765cc023f01e]:
[[file:cgs2023.pdf]]

*** CCT2019
cite:calonico2019regression[fn:d] consider 4 variations of
the Lee data by adding a pre-determined binary covariate
(previous democratic share). Each model includes this
covariate differently. For DGP 1, the covariate is
irrelevant and the DGP is the same as the classic Lee data
DGP. For the others, the covariate is relevant. For all
three, $X$ and $W$ follow:

#+BEGIN_SRC latex
  \begin{equation}
    \begin{split}
      w_r &= 0.49 + (1.06-0.45) x + (5.74-5.51) x^2 \\
      &+ (17.14-20.60) x^3 + (19.75-13.32) x^4 + (7.47-10.95) x^5 + \varepsilon_w\\
      w_l &= 0.49 + 1.06 x + 5.74 x^2 + 17.14 x^3 + 19.75 x^4 + 7.47 x^5 + \varepsilon_w\\
      y_r &= 0.38 + 0.63 x - 2.85 x^2 + 8.43 x^3 - 10.24 x^4 + 4.32 x^5 + 0.28 w_r + \varepsilon_y\\
      y_l &= 0.36 + 0.96 x + 5.47 x^2 + 15.28 x^3 + 15.87 x^4 + 5.14 x^5 + 0.22 w_l + \varepsilon_y\\
      \sigma_y &= 0.1295\\
      \sigma_w &= 0.13537.
    \end{split}
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \begin{split}
    w_r &= 0.49 + (1.06-0.45) x + (5.74-5.51) x^2 \\
    &+ (17.14-20.60) x^3 + (19.75-13.32) x^4 + (7.47-10.95) x^5 + \varepsilon_w\\
    w_l &= 0.49 + 1.06 x + 5.74 x^2 + 17.14 x^3 + 19.75 x^4 + 7.47 x^5 + \varepsilon_w\\
    y_r &= 0.38 + 0.63 x - 2.85 x^2 + 8.43 x^3 - 10.24 x^4 + 4.32 x^5 + 0.28 w_r + \varepsilon_y\\
    y_l &= 0.36 + 0.96 x + 5.47 x^2 + 15.28 x^3 + 15.87 x^4 + 5.14 x^5 + 0.22 w_l + \varepsilon_y\\
    \sigma_y &= 0.1295\\
    \sigma_w &= 0.13537.
  \end{split}
\end{equation}
#+end_export

This implies:

#+BEGIN_SRC latex
  \begin{equation}
    \begin{split}
      y &= \mu(x,\varepsilon_w) + \tau(x,\varepsilon_w)z + \varepsilon_y\\
      \mu(x,\varepsilon_w) &= 0.47 + 1.19 x + 6.73 x^2 + 19.05 x^3 + 20.21 x^4 + 6.78 x^5 + 0.22 \varepsilon_w\\
      \tau(x,\varepsilon_w) &= 0.049 - 0.36 x - 0.87 x^2 - 10.35 x^3 - 27.85 x^4 - 2.78 x^5 + 0.06 \varepsilon_w.
    \end{split}
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \begin{split}
    y &= \mu(x,\varepsilon_w) + \tau(x,\varepsilon_w)z + \varepsilon_y\\
    \mu(x,\varepsilon_w) &= 0.47 + 1.19 x + 6.73 x^2 + 19.05 x^3 + 20.21 x^4 + 6.78 x^5 + 0.22 \varepsilon_w\\
    \tau(x,\varepsilon_w) &= 0.049 - 0.36 x - 0.87 x^2 - 10.35 x^3 - 27.85 x^4 - 2.78 x^5 + 0.06 \varepsilon_w.
  \end{split}
\end{equation}
#+end_export

What differs from one DGP to the other is the joint
distribution of $\varepsilon_y,\varepsilon_w$:

1. DGP 2: $\sigma_{yw} = 0.2692 \sigma_y \sigma_w$
2. DGP 3: $\sigma_{yw} = 0$
3. DGP 4: $\sigma_{yw} = 0.5384 \sigma_y \sigma_w$

In each case, $\varepsilon_y,\varepsilon_w$ are sampled
jointly from a Gaussian with covariance:

#+BEGIN_SRC latex
  \begin{equation}
    \Sigma = \begin{pmatrix}
      \sigma_y^2 & \sigma_{yw}\\
      \sigma_{yw} & \sigma_w^2
    \end{pmatrix}.
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \Sigma = \begin{pmatrix}
    \sigma_y^2 & \sigma_{yw}\\
    \sigma_{yw} & \sigma_w^2
  \end{pmatrix}.
\end{equation}
#+end_export

This is what the data looks like:

#+BEGIN_SRC R :results output file graphics :file ccft2019.pdf
  set.seed(0)
  n <- 500
  x <- 2*rbeta(n,2,4)-1
  z <- as.numeric(x>=0)
  sig.y <- 0.1295
  sig.w <- 0.13537
  s2 <- matrix(c(sig.y^2,0.2692*sig.y*sig.w,0.2692*sig.y*sig.w,sig.w^2),2,2,byrow=T)
  s3 <- matrix(c(sig.y^2,0,0,sig.w^2),2,2,byrow=T)
  s4 <- matrix(c(sig.y^2,0.5384*sig.y*sig.w,0.5384*sig.y*sig.w,sig.w^2),2,2,byrow=T)
  e1 <- rnorm(n,0,sig.y)
  e2 <- mnormt::rmnorm(n,rep(0,2),s2)
  e3 <- mnormt::rmnorm(n,rep(0,2),s3)
  e4 <- mnormt::rmnorm(n,rep(0,2),s4)
  mu <- function(x,e) 0.47 + 1.19*x + 6.73*x^2 + 19.05*x^3 + 20.21*x^4 + 6.78*x^5 + 0.22*e
  tau <- function(x,e) 0.049 - 0.36*x - 0.87*x^2 - 10.35*x^3 - 27.85*x^4 - 2.78*x^5 + 0.06*e
  y1 <- mu(x,0) + tau(x,0)*z + e1
  y2 <- mu(x,e2[,2]) + tau(x,e2[,2])*z + e2[,1]
  y3 <- mu(x,e3[,2]) + tau(x,e3[,2])*z + e3[,1]
  y4 <- mu(x,e4[,2]) + tau(x,e4[,2])*z + e4[,1]
  ##
  par(mfrow=c(2,2))
  plot(x,y1,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y2,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y3,xlab="X",ylab="Y",col=z+1,bty="n")
  plot(x,y4,xlab="X",ylab="Y",col=z+1,bty="n")
#+END_SRC

#+RESULTS[6287fd71c16712a07fd3ec93082bd058a9c5136a]:
[[file:ccft2019.pdf]]

*** FH2019
cite:frolich2019including analyze a setup where the
additional covariates might be discontinuous at the
cutoff. The DGP follows:

#+BEGIN_SRC latex
  \begin{equation}
    \begin{split}
      X,U_1,U_2,U_3 &\sim \mathcal{N}(0,1)\\
      Z &= \mathbf{1}(X \geq 0)\\
      W_1 &= \alpha Z + 0.5 U_1\\
      W_2 &= \alpha Z + 0.5 U_2\\
      \mu(x,w) &= \beta(w_1+w_2) + \frac{\beta}{2}(w_1^2+w_2^2) + 0.5 x + 0.25 x^2\\
      \tau(x) &= 1 - 0.25 x\\
      y &= \mu(x,w) + \tau(x) z + u_3\\
      \alpha &\in \{0,0.2\}\\
      \beta &= 0.4.
    \end{split}
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \begin{split}
    X,U_1,U_2,U_3 &\sim \mathcal{N}(0,1)\\
    Z &= \mathbf{1}(X \geq 0)\\
    W_1 &= \alpha Z + 0.5 U_1\\
    W_2 &= \alpha Z + 0.5 U_2\\
    \mu(x,w) &= \beta(w_1+w_2) + \frac{\beta}{2}(w_1^2+w_2^2) + 0.5 x + 0.25 x^2\\
    \tau(x) &= 1 - 0.25 x\\
    y &= \mu(x,w) + \tau(x) z + u_3\\
    \alpha &\in \{0,0.2\}\\
    \beta &= 0.4.
  \end{split}
\end{equation}
#+end_export

This is what that DGP looks like for both values of
$\alpha$:

#+BEGIN_SRC R :results output file graphics :file FH2019.pdf
  set.seed(0)
  n <- 500
  x <- rnorm(n)
  u1 <- rnorm(n)
  u2 <- rnorm(n)
  u3 <- rnorm(n)
  z <- as.numeric(x>=0)
  w1 <- cbind(0.5*u1,0.5*u2)
  w2 <- cbind(0.2*z+0.5*u1,0.2*z+0.5*u2)
  mu <- function(x,w) 0.4*rowSums(w) + 0.2*rowSums(w^2) + 0.5*x + 0.25*x^2
  tau <- function(x) 1 - 0.25*x
  y1 <- mu(x,w1) + tau(x)*z + u3
  y2 <- mu(x,w2) + tau(x)*z + u3
  ##
  par(mfrow=c(2,1))
  plot(x,y1,col=z+1,xlab="X",ylab="Y",main=expression(alpha=0),bty="n")
  plot(x,y2,col=z+1,xlab="X",ylab="Y",main=expression(alpha=0.2),bty="n")
#+END_SRC

#+RESULTS[e3b377b21fbfefae8d2cccbd40075b9b08554db1]:
[[file:FH2019.pdf]]

*** KR2023
cite:kreiss2021inference also consider a polynomial DGP but
$W,\varepsilon$ are sampled jointly.
#+BEGIN_SRC latex
  \begin{equation}
    \begin{split}
      p &= 200\\
      X &\sim 2 \mathcal{B}(2,4) - 1\\
      Z &= \mathbf{1}(X \geq 0)\\
      (\varepsilon,W^T)^T &\sim \mathcal{N}(\mathbf{0},\Sigma)\\
      \Sigma &= \begin{pmatrix}
	\sigma^2_{\varepsilon} & \nu^T\\
	\nu & \sigma^2_W I_p
      \end{pmatrix}\\
      \mu(X,W) &= 0.36 + 0.96 X + 5.47 X^2 + 15.28 X^3 + 15.87 X^4 + 5.14 X^5 + 0.22 W^T \alpha\\
      \tau(X,W) &= 0.02 - 0.34 X - 8.31 X^2 - 6.86 X^3 - 26.11 X^4 - 0.83 X^5 + 0.06 W^T \alpha\\
      \sigma_{\varepsilon} &= 0.1295\\
      \sigma_W &= 0.1353\\
      \nu &\in \mathcal{R}^{200}, \quad \nu_k = \frac{0.8 \sqrt{6}\sigma^2_{\varepsilon}}{\pi k}\\
      \alpha &\in \mathcal{R}^{200}, \quad \alpha_k = \frac{2}{k^2}\\
      Y &= \mu(X,W) + \tau(X,W) Z + \varepsilon.
    \end{split}
  \end{equation}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{equation}
  \begin{split}
    p &= 200\\
    X &\sim 2 \mathcal{B}(2,4) - 1\\
    Z &= \mathbf{1}(X \geq 0)\\
    (\varepsilon,W^T)^T &\sim \mathcal{N}(\mathbf{0},\Sigma)\\
    \Sigma &= \begin{pmatrix}
      \sigma^2_{\varepsilon} & \nu^T\\
      \nu & \sigma^2_W I_p
    \end{pmatrix}\\
    \mu(X,W) &= 0.36 + 0.96 X + 5.47 X^2 + 15.28 X^3 + 15.87 X^4 + 5.14 X^5 + 0.22 W^T \alpha\\
    \tau(X,W) &= 0.02 - 0.34 X - 8.31 X^2 - 6.86 X^3 - 26.11 X^4 - 0.83 X^5 + 0.06 W^T \alpha\\
    \sigma_{\varepsilon} &= 0.1295\\
    \sigma_W &= 0.1353\\
    \nu &\in \mathcal{R}^{200}, \quad \nu_k = \frac{0.8 \sqrt{6}\sigma^2_{\varepsilon}}{\pi k}\\
    \alpha &\in \mathcal{R}^{200}, \quad \alpha_k = \frac{2}{k^2}\\
    Y &= \mu(X,W) + \tau(X,W) Z + \varepsilon.
  \end{split}
\end{equation}
#+end_export

This is what the errors and data looks like:

#+BEGIN_SRC R :results output file graphics :file KR2023.pdf
  set.seed(0)
  n <- 500
  p <- 200
  X <- 2*rbeta(n,2,4) - 1
  Z <- as.numeric(X>=0)
  sig.e <- 0.1295^2
  sig.w <- 0.1353^2
  nu <- 0.8*sqrt(6)*sig.e/(pi*1:p)
  alpha <- 2/(1:p)^2
  Sigma <- cbind(sig.e,t(nu))
  Sigma <- rbind(Sigma,cbind(nu,sig.w*diag(p)))
  temp <- MASS::mvrnorm(n,rep(0,p+1),Sigma)
  W <- temp[,-1]
  e <- temp[,1]
  mu <- function(X,W) 0.36 + 0.96*X + 5.47*X^2 + 15.28*X^3 + 15.87*X^4 + 5.14*X^5 + 0.22*W%*%alpha
  tau <- function(X,W) 0.02 - 0.34*X - 8.31*X^2 - 6.86*X^3 - 26.11*X^4 - 0.83*X^5 + 0.06*W%*%alpha
  Y <- mu(X,W) + tau(X,W)*Z + e
  ##
  par(mfrow=c(2,1))
  hist(e,main="")
  plot(X,Y,xlab="X",ylab="Y",col=Z+1,bty="n")
#+END_SRC

#+RESULTS[7bdd3d7ecf07090cc445c798275ce3bd2a14e238]:
[[file:KR2023.pdf]]

*** Reguly2021
cite:reguly2021heterogeneous fits a CART model to additional
covariates and performs node-level polynomial regressions on
X. He takes 1000 samples of each DGP and considers $n \in
\{1000,5000,10000\}$. Importantly, he samples $(X,W)$ only
once so that the variation across MCMC samples comes only
from $\varepsilon$ and his treatment effect function
includes only $W$ and not $X$.

1. DGP 1:
   - $X \sim U(-1,1)$
   - $W_1,W_2 \sim \text{Bernoulli}(0.5)$
   - $\mu(x) = 2x$
   - $\tau(w_1) = 2 w_1 - 1$
   - $\varepsilon \sim \mathcal{N}(0,1)$
2. DGP 2:
   - $X \sim U(-1,1)$
   - $W_1,W_2 \sim \text{Bernoulli}(0.5)$
   - $W_3,W_4 \sim U(-5,5)$
   - $\mu(x,w) = (4 w_2 - 2) x$
   - $\tau(w_3) = 2 w_3$
   - $\varepsilon \sim \mathcal{N}(0,1)$
3. DGP 3 (variation of Lee data):
   - $X \sim 2 \mathcal{B}(2,4)-1$
   - $W_1 \sim \text{Bernoulli}(0.5)$
   - $\mu(x,w_1) = 0.48 + w_1(1.27 x + 7.18 x^2 + 20.21
     x^3 + 21.54 x^4 + 7.33 x^5) +(1-w_1)(2.35 x +
     8.18 x^2 + 22.21 x^3 + 24.14 x^4 + 8.33 x^5)$
   - $\tau(x,w_1) = w_1(0.02 - 0.43 x - 10.18 x^2 - 12.22
     x^3 - 12.53 x^4 - 3.77 x^5) + (1-w_1)(0.07 - 1.14 x -
     11.08 x^2 - 15.22 x^3 - 14.13 x^4 - 3.77 x^5)$
   - $\varepsilon \sim \mathcal{N}(0,0.05)$
4. DGP 4 (variation of LM data)
   - $X \sim 2 \mathcal{B}(2,4)-1$
   - $W_1 \sim U(5,9)$
   - $\mu(x) = 3.71 + 2.30 x + 3.28 x^2 + 1.45 x^3 + 0.23
     x^4 + 0.03 x^5$
   - $\tau(w_1) = -0.45 + 16.19 x - 58.09 x^2 + 72.85 x^3 - 45.25
     x^4 + 9.8 x^5 - w_1$
   - $\varepsilon \sim \mathcal{N}(0,0.05)$
5. DGP 5: DGP 3 of cite:calonico2014robust

This is what the DGPs look like[fn:e]:

#+BEGIN_SRC R :results output file graphics :file reguly.pdf
      set.seed(0)
      n <- 500
      x1 <- runif(n,-1,1)
      z1 <- as.numeric(x1>=0)
      x2 <- 2*rbeta(n,2,4)-1
      z2 <- as.numeric(x2>=0)
      w1 <- matrix(rbinom(2*n,1,0.5),n,2)
      w2 <- matrix(runif(2*n,-5,5),n,2)
      ##
      mu1 <- function(x) 2*x
      tau1 <- function(w) 2*w-1
      y1 <- mu1(x1) + tau1(w1[,1])*z1 + rnorm(n)
      mu2 <- function(x,w) (4*w-2)*x1
      tau2 <- function(w) 2*w
      y2 <- mu2(x1,w1[,2]) + tau2(w2[,1])*z1 + rnorm(n)
      mu3 <- function(x,w) 0.48 + w*(1.27*x + 7.18*x^2 + 20.21*x^3 + 21.54*x^4 + 7.33*x^5) +
			     (1-w)*(2.35*x + 8.18*x^2 + 22.21*x^3 + 24.14*x^4 + 8.33*x^5)
      tau3 <- function(x,w) w*(0.02 - 0.43*x - 10.18*x^2 - 12.22*x^3 - 12.53*x^4 - 3.77*x^5) +
			      (1-w)*(0.07 - 1.14*x - 11.08*x^2 - 15.22*x^3 - 14.13*x^4 - 3.77*x^5)
      y3 <- mu3(x2,w1[,1]) + tau3(x2,w1[,1])*z2 + rnorm(n,0,sqrt(0.05))
      mu4 <- function(x) 3.71 + 2.30*x + 3.28*x^2 + 1.45*x^3 + 0.23*x^4 + 0.03*x^5
      tau4 <- function(x,w) -0.45 + 16.19*x - 58.09*x^2 + 72.85*x^3 - 45.25*x^4 + 9.8*x^5 - w
      y4 <- mu4(x2) + tau4(x2,w1[,1])*z2 + rnorm(n,0,sqrt(0.05))
      mu5 <- function(x) 0.48 + 1.27*x - 3.59*x^2 + 14.147*x^3 + 23.694*x^4 + 10.995*x^5
      tau5 <- function(x) 0.04 - 0.43*x + 3.29*x^2 - 16.544*x^3 - 24.595*x^4 - 7.435*x^5
      y5 <- mu5(x2) + tau5(x2)*z2 + rnorm(n,0,sqrt(0.05))
      ##
      par(mfrow=c(2,3))
      plot(x1,y1,xlab="X",ylab="Y",col=z1+1,bty="n")
      plot(x1,y2,xlab="X",ylab="Y",col=z1+1,bty="n")
      plot(x2,y3,xlab="X",ylab="Y",col=z2+1,bty="n")
      plot(x2,y4,xlab="X",ylab="Y",col=z2+1,bty="n")
      plot(x2,y5,xlab="X",ylab="Y",col=z2+1,bty="n")
#+END_SRC

#+RESULTS[3c7e8614b544a6fa1ac04fdd38d79fae70462399]:
[[file:reguly.pdf]]

Two things to note about this exercise. In DGP 1, we have
$\tau(w=1) = 1$, $\tau(w=0)=-1$ and $E[\tau]=0$. It might be
interesting to include a case with zero ATE but some
non-zero CATE to be estimated in our setup. In DGP 2, a
similar thing happens but now with continuous CATE. The way
$\tau$ is constructed is such that the continuous $W$
introduces huge variability in it, this is something to keep
in my mind when writing these simulations.

* Footnotes
[fn:a] Every simulation based on ``Lee data'' refers to this

[fn:b] Simulations detailed in supplemental material

[fn:c] Every simulation based on ``LM data'' refers to this

[fn:d] [[https://github.com/rdpackages-replication/CCFT_2019_RESTAT/blob/master/CCFT_2019_RESTAT_simuls.do]]

[fn:e] DGP 3 and 4 look different from the paper. The former
looks similar when using smaller sample sizes and the
conversion from $\mu_0,\mu_1$ to $\mu,\tau$ is correct. The
latter had a typo in the paper so the one written here is a
guess. I could not find the simulation codes for the paper
to check this
